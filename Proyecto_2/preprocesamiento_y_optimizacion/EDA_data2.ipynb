{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2-Parte II (Core)\n",
    "## Proyecto 2: Análisis y Selección de Problema\n",
    "\n",
    "### Parte II: Preprocesamiento y Optimización\n",
    "\n",
    "**Objetivo:** Realizar el preprocesamiento de datos y la optimización de modelos de machine learning para el conjunto de datos seleccionado. La meta es elegir la técnica de machine learning más adecuada y optimizar sus hiperparámetros para obtener el mejor rendimiento posible.\n",
    "\n",
    "---\n",
    "\n",
    "### Instrucciones Detalladas\n",
    "\n",
    "#### Parte 1: Preprocesamiento de Datos\n",
    "\n",
    "1. **Limpieza de Datos:**\n",
    "   - Tratar los valores nulos utilizando técnicas adecuadas (imputación, eliminación, etc.).\n",
    "   - Manejar los outliers mediante técnicas de filtrado o transformación.\n",
    "\n",
    "2. **Transformación de Columnas:**\n",
    "   - Utilizar `ColumnTransformer` para aplicar transformaciones específicas a diferentes columnas.\n",
    "   - Realizar codificación de variables categóricas utilizando técnicas como One-Hot Encoding.\n",
    "   - Escalar las variables numéricas usando `StandardScaler` u otros métodos de normalización.\n",
    "\n",
    "3. **Creación de Pipelines:**\n",
    "   - Crear pipelines utilizando `Pipeline` de `sklearn` para automatizar el preprocesamiento de datos y asegurar la reproducibilidad.\n",
    "   - Incluir todos los pasos de preprocesamiento en el pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 2: Selección de Técnica de Machine Learning\n",
    "\n",
    "1. **Entrenamiento Inicial:**\n",
    "   - Entrenar múltiples modelos de machine learning (por ejemplo, Regresión Lineal, KNN, Árbol de Decisión, Random Forest, XGBoost, LGBM).\n",
    "   - Evaluar los modelos utilizando validación cruzada y seleccionar el modelo con el mejor rendimiento inicial.\n",
    "\n",
    "2. **Comparación de Modelos:**\n",
    "   - Comparar los modelos utilizando métricas de rendimiento relevantes (exactitud, precisión, recall, F1-Score, ROC-AUC, etc.).\n",
    "   - Seleccionar la técnica de machine learning más adecuada basándose en las métricas y la naturaleza del problema.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 3: Optimización de Hiperparámetros\n",
    "\n",
    "1. **GridSearchCV:**\n",
    "   - Implementar `GridSearchCV` para realizar una búsqueda exhaustiva de los mejores hiperparámetros para el modelo seleccionado.\n",
    "   - Definir el espacio de búsqueda para los hiperparámetros relevantes.\n",
    "\n",
    "2. **RandomizedSearchCV:**\n",
    "   - Implementar `RandomizedSearchCV` para realizar una búsqueda aleatoria de los mejores hiperparámetros, especialmente útil si el espacio de búsqueda es grande.\n",
    "\n",
    "3. **Optuna:**\n",
    "   - Implementar `Optuna` para una optimización avanzada de los hiperparámetros, aprovechando técnicas como la optimización bayesiana y el pruning.\n",
    "\n",
    "4. **Evaluación de Modelos Optimizados:**\n",
    "   - Entrenar el modelo con los mejores hiperparámetros encontrados y evaluar su rendimiento en el conjunto de prueba.\n",
    "   - Comparar el rendimiento del modelo optimizado con el modelo inicial.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 4: Documentación y Entrega\n",
    "\n",
    "1. **Documentación del Proceso:**\n",
    "   - Documentar todos los pasos del preprocesamiento, selección de técnica y optimización en un notebook de Jupyter.\n",
    "   - Incluir explicaciones detalladas y justificaciones para cada decisión tomada.\n",
    "\n",
    "2. **Subida a GitHub:**\n",
    "   - Actualizar el repositorio de GitHub con los notebooks de preprocesamiento, selección de técnica y optimización.\n",
    "   - Incluir los resultados de la optimización y la comparación de modelos.\n",
    "   - Crear un tag de liberación (`v2.0.0`) para esta versión del proyecto.\n",
    "\n",
    "---\n",
    " **Estructura del Repositorio en GitHub**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fuente:** [UCI Machine Learning Repository: Zoo Dataset](https://archive.ics.uci.edu/ml/datasets/Zoo)  \n",
    "**Acerca del conjunto de datos:**  \n",
    "Este conjunto de datos contiene información sobre 101 animales del zoológico, con 16 variables que describen diversas características. La finalidad de este dataset es predecir la clasificación de los animales en 7 clases diferentes: Mamífero, Ave, Reptil, Pez, Anfibio, Insecto e Invertebrado. Es un dataset ideal para quienes están aprendiendo Machine Learning.\n",
    "\n",
    "## Tamaño y Variables\n",
    "\n",
    "El dataset principal está compuesto por las siguientes columnas:\n",
    "\n",
    "| **Columna**      | **Descripción**                                                                                     |\n",
    "|------------------|---------------------------------------------------------------------------------------------------|\n",
    "| `animal_name`    | Nombre único para cada animal.                                                                     |\n",
    "| `hair`           | Indica si el animal tiene cabello (`True/False`).                                                  |\n",
    "| `feathers`       | Indica si el animal tiene plumas (`True/False`).                                                   |\n",
    "| `eggs`           | Indica si el animal pone huevos (`True/False`).                                                    |\n",
    "| `milk`           | Indica si el animal produce leche (`True/False`).                                                  |\n",
    "| `airborne`       | Indica si el animal puede volar (`True/False`).                                                    |\n",
    "| `aquatic`        | Indica si el animal vive en el agua (`True/False`).                                                |\n",
    "| `predator`       | Indica si el animal es un depredador (`True/False`).                                               |\n",
    "| `toothed`        | Indica si el animal tiene dientes (`True/False`).                                                  |\n",
    "| `backbone`       | Indica si el animal tiene columna vertebral (`True/False`).                                        |\n",
    "| `breathes`       | Indica si el animal respira aire (`True/False`).                                                   |\n",
    "| `venomous`       | Indica si el animal es venenoso (`True/False`).                                                    |\n",
    "| `fins`           | Indica si el animal tiene aletas (`True/False`).                                                   |\n",
    "| `legs`           | Número de patas del animal (valores posibles: {0, 2, 4, 5, 6, 8}).                                |\n",
    "| `tail`           | Indica si el animal tiene cola (`True/False`).                                                     |\n",
    "| `domestic`       | Indica si el animal es doméstico (`True/False`).                                                   |\n",
    "| `catsize`        | Indica si el animal es del tamaño de un gato (`True/False`).                                       |\n",
    "| `class_type`     | Tipo de clase del animal (valores numéricos en el rango [1, 7], TARGET).          |\n",
    "\n",
    "### Clases del Dataset\n",
    "\n",
    "| **Número de Clase** | **Descripción de la Clase**      | **Número de Especies** |\n",
    "|----------------------|----------------------------------|-------------------------|\n",
    "| 1                    | Mamífero                       |                         |\n",
    "| 2                    | Ave                            |                         |\n",
    "| 3                    | Reptil                         |                         |\n",
    "| 4                    | Pez                            |                         |\n",
    "| 5                    | Anfibio                        |                         |\n",
    "| 6                    | Insecto                        |                         |\n",
    "| 7                    | Invertebrado                   |                         |\n",
    "\n",
    "Este dataset es una herramienta útil para aprender conceptos básicos de clasificación en Machine Learning y comprender cómo diferentes características pueden ayudar a predecir la clase de un animal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESARROLLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Preprocesamiento de Datos\n",
    "\n",
    "1. **Limpieza de Datos:**\n",
    "   - Tratar los valores nulos utilizando técnicas adecuadas (imputación, eliminación, etc.).\n",
    "   - Manejar los outliers mediante técnicas de filtrado o transformación.\n",
    "\n",
    "2. **Transformación de Columnas:**\n",
    "   - Utilizar `ColumnTransformer` para aplicar transformaciones específicas a diferentes columnas.\n",
    "   - Realizar codificación de variables categóricas utilizando técnicas como One-Hot Encoding.\n",
    "   - Escalar las variables numéricas usando `StandardScaler` u otros métodos de normalización.\n",
    "\n",
    "3. **Creación de Pipelines:**\n",
    "   - Crear pipelines utilizando `Pipeline` de `sklearn` para automatizar el preprocesamiento de datos y asegurar la reproducibilidad.\n",
    "   - Incluir todos los pasos de preprocesamiento en el pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from utils import calculate_null, val_num_unicos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>animal_name</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>antelope</td>\n",
       "      <td>bass</td>\n",
       "      <td>bear</td>\n",
       "      <td>boar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feathers</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airborne</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquatic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predator</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toothed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breathes</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venomous</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fins</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tail</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domestic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catsize</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_type</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1     2     3     4\n",
       "animal_name  aardvark  antelope  bass  bear  boar\n",
       "hair                1         1     0     1     1\n",
       "feathers            0         0     0     0     0\n",
       "eggs                0         0     1     0     0\n",
       "milk                1         1     0     1     1\n",
       "airborne            0         0     0     0     0\n",
       "aquatic             0         0     1     0     0\n",
       "predator            1         0     1     1     1\n",
       "toothed             1         1     1     1     1\n",
       "backbone            1         1     1     1     1\n",
       "breathes            1         1     0     1     1\n",
       "venomous            0         0     0     0     0\n",
       "fins                0         0     1     0     0\n",
       "legs                4         4     0     4     4\n",
       "tail                0         1     1     0     1\n",
       "domestic            0         0     0     0     0\n",
       "catsize             1         1     0     1     1\n",
       "class_type          1         1     4     1     1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "data2 = pd.read_csv(\n",
    "    r'C:\\Users\\GIGABYTE\\Documents\\tareas_bootcamp_coding_dojo\\Proyecto_2\\data\\zoo.csv',\n",
    "    dtype={4: str}  # Aquí definimos que la columna 4 sea tratada como string\n",
    ")\n",
    "data2.head().T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   animal_name  101 non-null    object\n",
      " 1   hair         101 non-null    int64 \n",
      " 2   feathers     101 non-null    int64 \n",
      " 3   eggs         101 non-null    int64 \n",
      " 4   milk         101 non-null    object\n",
      " 5   airborne     101 non-null    int64 \n",
      " 6   aquatic      101 non-null    int64 \n",
      " 7   predator     101 non-null    int64 \n",
      " 8   toothed      101 non-null    int64 \n",
      " 9   backbone     101 non-null    int64 \n",
      " 10  breathes     101 non-null    int64 \n",
      " 11  venomous     101 non-null    int64 \n",
      " 12  fins         101 non-null    int64 \n",
      " 13  legs         101 non-null    int64 \n",
      " 14  tail         101 non-null    int64 \n",
      " 15  domestic     101 non-null    int64 \n",
      " 16  catsize      101 non-null    int64 \n",
      " 17  class_type   101 non-null    int64 \n",
      "dtypes: int64(16), object(2)\n",
      "memory usage: 14.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data2.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df.duplicated()\n",
    "# Contar el número de duplicados\n",
    "num_duplicados = duplicados.sum()\n",
    "print(f\"Número de registros duplicados: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datos sin NAs en q</th>\n",
       "      <th>Na en q</th>\n",
       "      <th>Na en %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>animal_name</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feathers</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airborne</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquatic</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predator</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toothed</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breathes</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venomous</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fins</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tail</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domestic</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catsize</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_type</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datos sin NAs en q  Na en q  Na en %\n",
       "animal_name                 101        0      0.0\n",
       "hair                        101        0      0.0\n",
       "feathers                    101        0      0.0\n",
       "eggs                        101        0      0.0\n",
       "milk                        101        0      0.0\n",
       "airborne                    101        0      0.0\n",
       "aquatic                     101        0      0.0\n",
       "predator                    101        0      0.0\n",
       "toothed                     101        0      0.0\n",
       "backbone                    101        0      0.0\n",
       "breathes                    101        0      0.0\n",
       "venomous                    101        0      0.0\n",
       "fins                        101        0      0.0\n",
       "legs                        101        0      0.0\n",
       "tail                        101        0      0.0\n",
       "domestic                    101        0      0.0\n",
       "catsize                     101        0      0.0\n",
       "class_type                  101        0      0.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar valores nulos\n",
    "calculate_null(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y la variable objetivo\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "X = df.drop(columns=['animal_name', 'class_type'])\n",
    "y = df['class_type']\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "numeric_features = X.select_dtypes(include=['int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Crear ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Selección de Técnica de Machine Learning\n",
    "\n",
    "1. **Entrenamiento Inicial:**\n",
    "   - Entrenar múltiples modelos de machine learning (por ejemplo, Regresión Lineal, KNN, Árbol de Decisión, Random Forest, XGBoost, LGBM).\n",
    "   - Evaluar los modelos utilizando validación cruzada y seleccionar el modelo con el mejor rendimiento inicial.\n",
    "\n",
    "2. **Comparación de Modelos:**\n",
    "   - Comparar los modelos utilizando métricas de rendimiento relevantes (exactitud, precisión, recall, F1-Score, ROC-AUC, etc.).\n",
    "   - Seleccionar la técnica de machine learning más adecuada basándose en las métricas y la naturaleza del problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo inicial: Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiendo inicial\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modelos iniciales con semilla fija\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Validación cruzada para cada modelo\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # Estratificación con semilla\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline.set_params(classifier=model)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "    results[name] = scores.mean()\n",
    "\n",
    "# Comparar resultados\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"Mejor modelo inicial: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "  accuracy: 0.9625\n",
      "  f1_macro: 0.8979\n",
      "  roc_auc: 0.9983\n",
      "\n",
      "Modelo: K-Nearest Neighbors\n",
      "  accuracy: 0.9250\n",
      "  f1_macro: 0.7979\n",
      "  roc_auc: 0.9798\n",
      "\n",
      "Modelo: Decision Tree\n",
      "  accuracy: 0.9748\n",
      "  f1_macro: 0.9556\n",
      "  roc_auc: 0.9782\n",
      "\n",
      "Modelo: Random Forest\n",
      "  accuracy: 0.9497\n",
      "  f1_macro: 0.8503\n",
      "  roc_auc: 0.9993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {'accuracy': 'accuracy', 'f1_macro': 'f1_macro', 'roc_auc': 'roc_auc_ovr'}\n",
    "metrics_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline.set_params(classifier=model)\n",
    "    scores = cross_validate(pipeline, X_train, y_train, cv=skf, scoring=scoring)\n",
    "    metrics_results[name] = {metric: scores[f'test_{metric}'].mean() for metric in scoring}\n",
    "\n",
    "# Comparar resultados\n",
    "for model_name, metrics in metrics_results.items():\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo según F1-Score: Decision Tree\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(metrics_results, key=lambda x: metrics_results[x]['f1_macro'])\n",
    "print(f\"Mejor modelo según F1-Score: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Métricas\n",
    "\n",
    "#### Logistic Regression\n",
    "- **accuracy:** 96.25% (Buena precisión general).\n",
    "- **f1_macro:** 89.79% (Indica un desempeño promedio para las clases desbalanceadas).\n",
    "- **roc_auc:** 99.83% (Excelente separación entre clases).\n",
    "\n",
    "#### K-Nearest Neighbors (KNN)\n",
    "- **accuracy:** 92.50% (Inferior a Logistic Regression y Decision Tree).\n",
    "- **f1_macro:** 79.79% (Rendimiento débil en clases desbalanceadas).\n",
    "- **roc_auc:** 97.98% (Bueno, pero inferior al Logistic Regression y Random Forest).\n",
    "\n",
    "#### Decision Tree\n",
    "- **accuracy:** 97.48% (La más alta entre los modelos).\n",
    "- **f1_macro:** 95.56% (Excelente manejo de clases desbalanceadas).\n",
    "- **roc_auc:** 97.82% (Adecuado, pero inferior a Logistic Regression y Random Forest).\n",
    "\n",
    "#### Random Forest\n",
    "- **accuracy:** 94.97% (Inferior a Logistic Regression y Decision Tree).\n",
    "- **f1_macro:** 85.03% (Mejor que KNN, pero no supera a Decision Tree).\n",
    "- **roc_auc:** 99.93% (La más alta, excelente separación entre clases).\n",
    "\n",
    "---\n",
    "\n",
    "### Selección del Modelo\n",
    "\n",
    "La selección del mejor modelo depende del objetivo principal:\n",
    "\n",
    "1. **Si la prioridad es la consistencia entre clases desbalanceadas:**\n",
    "   - El **Decision Tree** tiene el mejor **F1-Score (95.56%)** y la mejor precisión (**accuracy: 97.48%**) para un equilibrio entre métricas.\n",
    "\n",
    "2. **Si el enfoque es la separación entre clases (AUC):**\n",
    "   - **Random Forest** tiene el mejor **ROC-AUC (99.93%)**, pero su desempeño en F1-Score (85.03%) y precisión (94.97%) es inferior.\n",
    "\n",
    "3. **Si se busca un modelo simple con buen desempeño general:**\n",
    "   - **Logistic Regression** tiene un desempeño balanceado y alta interpretabilidad, aunque no es el mejor en F1-Score ni accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "#### Recomendación Final\n",
    "- **Mejor Modelo:** **Decision Tree**  \n",
    "   - **Razón:** Tiene el mejor F1-Score (manejo de clases desbalanceadas) y la mayor precisión general, lo que asegura un buen balance entre todas las métricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Optimización de Hiperparámetros\n",
    "\n",
    "1. **GridSearchCV:**\n",
    "   - Implementar `GridSearchCV` para realizar una búsqueda exhaustiva de los mejores hiperparámetros para el modelo seleccionado.\n",
    "   - Definir el espacio de búsqueda para los hiperparámetros relevantes.\n",
    "\n",
    "2. **RandomizedSearchCV:**\n",
    "   - Implementar `RandomizedSearchCV` para realizar una búsqueda aleatoria de los mejores hiperparámetros, especialmente útil si el espacio de búsqueda es grande.\n",
    "\n",
    "3. **Optuna:**\n",
    "   - Implementar `Optuna` para una optimización avanzada de los hiperparámetros, aprovechando técnicas como la optimización bayesiana y el pruning.\n",
    "\n",
    "4. **Evaluación de Modelos Optimizados:**\n",
    "   - Entrenar el modelo con los mejores hiperparámetros encontrados y evaluar su rendimiento en el conjunto de prueba.\n",
    "   - Comparar el rendimiento del modelo optimizado con el modelo inicial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros (RandomizedSearchCV): {'classifier__n_estimators': 200, 'classifier__min_samples_split': 2, 'classifier__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [10, 50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros (RandomizedSearchCV): {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 23:15:22,303] A new study created in memory with name: no-name-e62573d2-be98-4c4c-baff-d853acd23d25\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:22,804] Trial 0 finished with value: 0.975 and parameters: {'n_estimators': 104, 'max_depth': 26, 'min_samples_split': 2}. Best is trial 0 with value: 0.975.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:22,933] Trial 1 finished with value: 0.9375 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 0 with value: 0.975.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:23,763] Trial 2 finished with value: 0.9375 and parameters: {'n_estimators': 184, 'max_depth': 22, 'min_samples_split': 9}. Best is trial 0 with value: 0.975.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:24,063] Trial 3 finished with value: 0.9875 and parameters: {'n_estimators': 62, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:24,378] Trial 4 finished with value: 0.8875 and parameters: {'n_estimators': 60, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:25,096] Trial 5 finished with value: 0.9625 and parameters: {'n_estimators': 161, 'max_depth': 14, 'min_samples_split': 7}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:25,512] Trial 6 finished with value: 0.9375 and parameters: {'n_estimators': 89, 'max_depth': 21, 'min_samples_split': 8}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:25,734] Trial 7 finished with value: 0.95 and parameters: {'n_estimators': 40, 'max_depth': 27, 'min_samples_split': 3}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:26,097] Trial 8 finished with value: 0.9625 and parameters: {'n_estimators': 77, 'max_depth': 14, 'min_samples_split': 2}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:26,795] Trial 9 finished with value: 0.9375 and parameters: {'n_estimators': 154, 'max_depth': 10, 'min_samples_split': 9}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:27,428] Trial 10 finished with value: 0.95 and parameters: {'n_estimators': 134, 'max_depth': 15, 'min_samples_split': 5}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:27,995] Trial 11 finished with value: 0.9625 and parameters: {'n_estimators': 118, 'max_depth': 30, 'min_samples_split': 4}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:28,380] Trial 12 finished with value: 0.9625 and parameters: {'n_estimators': 68, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:28,916] Trial 13 finished with value: 0.9875 and parameters: {'n_estimators': 105, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:29,016] Trial 14 finished with value: 0.9625 and parameters: {'n_estimators': 11, 'max_depth': 12, 'min_samples_split': 5}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:29,295] Trial 15 finished with value: 0.975 and parameters: {'n_estimators': 49, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:29,729] Trial 16 finished with value: 0.95 and parameters: {'n_estimators': 93, 'max_depth': 16, 'min_samples_split': 5}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:30,328] Trial 17 finished with value: 0.9625 and parameters: {'n_estimators': 124, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:30,577] Trial 18 finished with value: 0.9625 and parameters: {'n_estimators': 39, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 3 with value: 0.9875.\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-11-26 23:15:31,228] Trial 19 finished with value: 0.975 and parameters: {'n_estimators': 144, 'max_depth': 12, 'min_samples_split': 3}. Best is trial 3 with value: 0.9875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros (Optuna): {'n_estimators': 62, 'max_depth': 13, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, log=True)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    pipeline.set_params(classifier__n_estimators=n_estimators,\n",
    "                        classifier__max_depth=max_depth,\n",
    "                        classifier__min_samples_split=min_samples_split)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f\"Mejores hiperparámetros (Optuna): {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.67      1.00      0.80         2\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.78      0.83      0.80        21\n",
      "weighted avg       0.92      0.95      0.93        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\GIGABYTE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Entrenar el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Mejores parámetros: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Crear el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo con la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ver los mejores hiperparámetros\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Mejores parámetros aleatorios: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 118}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Definir el espacio de búsqueda para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "# Crear el objeto RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_dist, n_iter=100, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo con RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ver los mejores parámetros\n",
    "print(f\"Mejores parámetros aleatorios: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 01:13:11,974] A new study created in memory with name: no-name-5a0b1c2f-3f68-4fcd-a4f4-45fb272e557e\n",
      "[I 2024-11-26 01:13:12,132] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 181, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,242] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 112, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,371] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 122, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,487] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,579] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 106, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,672] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,835] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 185, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:12,969] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,079] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 126, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,223] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 162, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,425] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,590] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 162, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,738] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:13,927] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 178, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,045] Trial 14 finished with value: 1.0 and parameters: {'n_estimators': 126, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,209] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 178, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,339] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 138, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,492] Trial 17 finished with value: 1.0 and parameters: {'n_estimators': 167, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,682] Trial 18 finished with value: 1.0 and parameters: {'n_estimators': 197, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,789] Trial 19 finished with value: 1.0 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:14,920] Trial 20 finished with value: 1.0 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,034] Trial 21 finished with value: 1.0 and parameters: {'n_estimators': 117, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,151] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 124, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,258] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 113, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,391] Trial 24 finished with value: 1.0 and parameters: {'n_estimators': 134, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,532] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 153, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,646] Trial 26 finished with value: 1.0 and parameters: {'n_estimators': 120, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,773] Trial 27 finished with value: 1.0 and parameters: {'n_estimators': 133, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:15,912] Trial 28 finished with value: 1.0 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,014] Trial 29 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,186] Trial 30 finished with value: 1.0 and parameters: {'n_estimators': 189, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,291] Trial 31 finished with value: 1.0 and parameters: {'n_estimators': 109, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,394] Trial 32 finished with value: 1.0 and parameters: {'n_estimators': 109, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,495] Trial 33 finished with value: 1.0 and parameters: {'n_estimators': 103, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,607] Trial 34 finished with value: 1.0 and parameters: {'n_estimators': 117, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,709] Trial 35 finished with value: 1.0 and parameters: {'n_estimators': 105, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,807] Trial 36 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:16,922] Trial 37 finished with value: 1.0 and parameters: {'n_estimators': 121, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,041] Trial 38 finished with value: 1.0 and parameters: {'n_estimators': 129, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,151] Trial 39 finished with value: 1.0 and parameters: {'n_estimators': 114, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,305] Trial 40 finished with value: 1.0 and parameters: {'n_estimators': 170, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,413] Trial 41 finished with value: 1.0 and parameters: {'n_estimators': 106, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,520] Trial 42 finished with value: 1.0 and parameters: {'n_estimators': 106, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,664] Trial 43 finished with value: 1.0 and parameters: {'n_estimators': 157, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,775] Trial 44 finished with value: 1.0 and parameters: {'n_estimators': 114, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:17,945] Trial 45 finished with value: 1.0 and parameters: {'n_estimators': 187, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,105] Trial 46 finished with value: 1.0 and parameters: {'n_estimators': 177, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,213] Trial 47 finished with value: 1.0 and parameters: {'n_estimators': 109, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,353] Trial 48 finished with value: 1.0 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,477] Trial 49 finished with value: 1.0 and parameters: {'n_estimators': 130, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,590] Trial 50 finished with value: 1.0 and parameters: {'n_estimators': 119, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,690] Trial 51 finished with value: 1.0 and parameters: {'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,794] Trial 52 finished with value: 1.0 and parameters: {'n_estimators': 105, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:18,903] Trial 53 finished with value: 1.0 and parameters: {'n_estimators': 112, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,021] Trial 54 finished with value: 1.0 and parameters: {'n_estimators': 123, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,134] Trial 55 finished with value: 1.0 and parameters: {'n_estimators': 117, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,239] Trial 56 finished with value: 1.0 and parameters: {'n_estimators': 108, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,338] Trial 57 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,491] Trial 58 finished with value: 1.0 and parameters: {'n_estimators': 163, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,670] Trial 59 finished with value: 1.0 and parameters: {'n_estimators': 197, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,792] Trial 60 finished with value: 1.0 and parameters: {'n_estimators': 126, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:19,960] Trial 61 finished with value: 1.0 and parameters: {'n_estimators': 184, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,119] Trial 62 finished with value: 1.0 and parameters: {'n_estimators': 173, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,287] Trial 63 finished with value: 1.0 and parameters: {'n_estimators': 183, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,389] Trial 64 finished with value: 1.0 and parameters: {'n_estimators': 103, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,500] Trial 65 finished with value: 1.0 and parameters: {'n_estimators': 111, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,676] Trial 66 finished with value: 1.0 and parameters: {'n_estimators': 194, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:20,850] Trial 67 finished with value: 1.0 and parameters: {'n_estimators': 192, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,022] Trial 68 finished with value: 1.0 and parameters: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,134] Trial 69 finished with value: 1.0 and parameters: {'n_estimators': 114, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,286] Trial 70 finished with value: 1.0 and parameters: {'n_estimators': 136, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,431] Trial 71 finished with value: 1.0 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,580] Trial 72 finished with value: 1.0 and parameters: {'n_estimators': 158, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,734] Trial 73 finished with value: 1.0 and parameters: {'n_estimators': 166, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:21,874] Trial 74 finished with value: 1.0 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,036] Trial 75 finished with value: 1.0 and parameters: {'n_estimators': 174, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,142] Trial 76 finished with value: 1.0 and parameters: {'n_estimators': 107, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,247] Trial 77 finished with value: 1.0 and parameters: {'n_estimators': 103, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,382] Trial 78 finished with value: 1.0 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,496] Trial 79 finished with value: 1.0 and parameters: {'n_estimators': 116, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,605] Trial 80 finished with value: 1.0 and parameters: {'n_estimators': 111, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,731] Trial 81 finished with value: 1.0 and parameters: {'n_estimators': 131, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,849] Trial 82 finished with value: 1.0 and parameters: {'n_estimators': 122, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:22,951] Trial 83 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,072] Trial 84 finished with value: 1.0 and parameters: {'n_estimators': 126, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,246] Trial 85 finished with value: 1.0 and parameters: {'n_estimators': 188, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,350] Trial 86 finished with value: 1.0 and parameters: {'n_estimators': 105, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,460] Trial 87 finished with value: 1.0 and parameters: {'n_estimators': 109, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,574] Trial 88 finished with value: 1.0 and parameters: {'n_estimators': 118, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,686] Trial 89 finished with value: 1.0 and parameters: {'n_estimators': 115, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,788] Trial 90 finished with value: 1.0 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:23,936] Trial 91 finished with value: 1.0 and parameters: {'n_estimators': 157, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,075] Trial 92 finished with value: 1.0 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,226] Trial 93 finished with value: 1.0 and parameters: {'n_estimators': 161, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,370] Trial 94 finished with value: 1.0 and parameters: {'n_estimators': 152, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,538] Trial 95 finished with value: 1.0 and parameters: {'n_estimators': 181, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,697] Trial 96 finished with value: 1.0 and parameters: {'n_estimators': 169, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:24,878] Trial 97 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:25,048] Trial 98 finished with value: 1.0 and parameters: {'n_estimators': 186, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-11-26 01:13:25,221] Trial 99 finished with value: 1.0 and parameters: {'n_estimators': 191, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de Optuna: {'n_estimators': 181, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 9}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir la función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 200),\n",
    "        max_depth=trial.suggest_categorical('max_depth', [None, 10, 20, 30]),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "# Crear el estudio de Optuna y optimizar\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Ver los mejores hiperparámetros\n",
    "print(f\"Mejores parámetros de Optuna: {study.best_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
