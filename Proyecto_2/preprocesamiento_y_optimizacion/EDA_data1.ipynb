{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2-Parte II (Core)\n",
    "## Proyecto 2: Análisis y Selección de Problema\n",
    "\n",
    "### Parte II: Preprocesamiento y Optimización\n",
    "\n",
    "**Objetivo:** Realizar el preprocesamiento de datos y la optimización de modelos de machine learning para el conjunto de datos seleccionado. La meta es elegir la técnica de machine learning más adecuada y optimizar sus hiperparámetros para obtener el mejor rendimiento posible.\n",
    "\n",
    "---\n",
    "\n",
    "### Instrucciones Detalladas\n",
    "\n",
    "#### Parte 1: Preprocesamiento de Datos\n",
    "\n",
    "1. **Limpieza de Datos:**\n",
    "   - Tratar los valores nulos utilizando técnicas adecuadas (imputación, eliminación, etc.).\n",
    "   - Manejar los outliers mediante técnicas de filtrado o transformación.\n",
    "\n",
    "2. **Transformación de Columnas:**\n",
    "   - Utilizar `ColumnTransformer` para aplicar transformaciones específicas a diferentes columnas.\n",
    "   - Realizar codificación de variables categóricas utilizando técnicas como One-Hot Encoding.\n",
    "   - Escalar las variables numéricas usando `StandardScaler` u otros métodos de normalización.\n",
    "\n",
    "3. **Creación de Pipelines:**\n",
    "   - Crear pipelines utilizando `Pipeline` de `sklearn` para automatizar el preprocesamiento de datos y asegurar la reproducibilidad.\n",
    "   - Incluir todos los pasos de preprocesamiento en el pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 2: Selección de Técnica de Machine Learning\n",
    "\n",
    "1. **Entrenamiento Inicial:**\n",
    "   - Entrenar múltiples modelos de machine learning (por ejemplo, Regresión Lineal, KNN, Árbol de Decisión, Random Forest, XGBoost, LGBM).\n",
    "   - Evaluar los modelos utilizando validación cruzada y seleccionar el modelo con el mejor rendimiento inicial.\n",
    "\n",
    "2. **Comparación de Modelos:**\n",
    "   - Comparar los modelos utilizando métricas de rendimiento relevantes (exactitud, precisión, recall, F1-Score, ROC-AUC, etc.).\n",
    "   - Seleccionar la técnica de machine learning más adecuada basándose en las métricas y la naturaleza del problema.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 3: Optimización de Hiperparámetros\n",
    "\n",
    "1. **GridSearchCV:**\n",
    "   - Implementar `GridSearchCV` para realizar una búsqueda exhaustiva de los mejores hiperparámetros para el modelo seleccionado.\n",
    "   - Definir el espacio de búsqueda para los hiperparámetros relevantes.\n",
    "\n",
    "2. **RandomizedSearchCV:**\n",
    "   - Implementar `RandomizedSearchCV` para realizar una búsqueda aleatoria de los mejores hiperparámetros, especialmente útil si el espacio de búsqueda es grande.\n",
    "\n",
    "3. **Optuna:**\n",
    "   - Implementar `Optuna` para una optimización avanzada de los hiperparámetros, aprovechando técnicas como la optimización bayesiana y el pruning.\n",
    "\n",
    "4. **Evaluación de Modelos Optimizados:**\n",
    "   - Entrenar el modelo con los mejores hiperparámetros encontrados y evaluar su rendimiento en el conjunto de prueba.\n",
    "   - Comparar el rendimiento del modelo optimizado con el modelo inicial.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parte 4: Documentación y Entrega\n",
    "\n",
    "1. **Documentación del Proceso:**\n",
    "   - Documentar todos los pasos del preprocesamiento, selección de técnica y optimización en un notebook de Jupyter.\n",
    "   - Incluir explicaciones detalladas y justificaciones para cada decisión tomada.\n",
    "\n",
    "2. **Subida a GitHub:**\n",
    "   - Actualizar el repositorio de GitHub con los notebooks de preprocesamiento, selección de técnica y optimización.\n",
    "   - Incluir los resultados de la optimización y la comparación de modelos.\n",
    "   - Crear un tag de liberación (`v2.0.0`) para esta versión del proyecto.\n",
    "\n",
    "---\n",
    " **Estructura del Repositorio en GitHub**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Conjunto de Datos de Seguro de Salud**\n",
    "Este conjunto de datos tiene como objetivo predecir los costos del seguro de salud en función de diversas características del asegurado. \n",
    "\n",
    "[Medical Cost Personal Datasets](https://www.kaggle.com/datasets/mirichoi0218/insurance)\n",
    "\n",
    "---\n",
    "\n",
    "### Contexto:\n",
    "El conjunto de datos contiene información sobre beneficiarios de seguros de salud y sus características, tales como edad, sexo, índice de masa corporal (IMC), número de hijos cubiertos, si fuman o no, la región de residencia, y los costos médicos facturados por el seguro.\n",
    "\n",
    "### Columnas:\n",
    "- **age**: Edad del asegurado.\n",
    "- **sex**: Género del asegurado (masculino, femenino).\n",
    "- **bmi**: Índice de masa corporal.\n",
    "- **children**: Número de dependientes cubiertos por el seguro.\n",
    "- **smoker**: Indica si el asegurado fuma o no.\n",
    "- **region**: Área residencial del asegurado en EE. UU. (noreste, sureste, suroeste, noroeste).\n",
    "- **charges**: Costos médicos facturados por el seguro de salud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESARROLLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Preprocesamiento de Datos\n",
    "\n",
    "1. **Limpieza de Datos:**\n",
    "   - Tratar los valores nulos utilizando técnicas adecuadas (imputación, eliminación, etc.).\n",
    "   - Manejar los outliers mediante técnicas de filtrado o transformación.\n",
    "\n",
    "2. **Transformación de Columnas:**\n",
    "   - Utilizar `ColumnTransformer` para aplicar transformaciones específicas a diferentes columnas.\n",
    "   - Realizar codificación de variables categóricas utilizando técnicas como One-Hot Encoding.\n",
    "   - Escalar las variables numéricas usando `StandardScaler` u otros métodos de normalización.\n",
    "\n",
    "3. **Creación de Pipelines:**\n",
    "   - Crear pipelines utilizando `Pipeline` de `sklearn` para automatizar el preprocesamiento de datos y asegurar la reproducibilidad.\n",
    "   - Incluir todos los pasos de preprocesamiento en el pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('C:/Users/GIGABYTE/Documents/tareas_bootcamp_coding_dojo/Proyecto_2')\n",
    "# Importar las funciones desde el archivo utils.py\n",
    "from utils import calculate_null, val_cat_unicos\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Importar modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'verbosity': -1,\n",
    "    'learning_rate': 0.05  # Ajusta este valor\n",
    "}\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.9</td>\n",
       "      <td>33.77</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.705</td>\n",
       "      <td>28.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>southwest</td>\n",
       "      <td>southeast</td>\n",
       "      <td>southeast</td>\n",
       "      <td>northwest</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1          2            3          4\n",
       "age              19         18         28           33         32\n",
       "sex          female       male       male         male       male\n",
       "bmi            27.9      33.77       33.0       22.705      28.88\n",
       "children          0          1          3            0          0\n",
       "smoker          yes         no         no           no         no\n",
       "region    southwest  southeast  southeast    northwest  northwest\n",
       "charges   16884.924  1725.5523   4449.462  21984.47061  3866.8552"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "data1 = pd.read_csv(\n",
    "    r'C:\\\\Users\\\\GIGABYTE\\\\Documents\\\\tareas_bootcamp_coding_dojo\\\\Proyecto_2\\\\data\\\\insurance.csv',\n",
    "    encoding='latin1'\n",
    ")\n",
    "data1.head().T  # Primeras 5 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas del dataset\n",
    "data1.columns = (\n",
    "    data1.columns\n",
    "    .str.strip()               # Elimina espacios iniciales y finales\n",
    "    .str.replace(\"'\", \"\")      # Elimina comillas simples\n",
    "    .str.replace(\"-\", \"_\")     # Reemplaza guiones por guiones bajos\n",
    "    .str.replace(\" \", \"_\")     # Reemplaza espacios por guiones bajos\n",
    "    .str.lower()               # Convierte todo a minúsculas\n",
    ")\n",
    "\n",
    "# Mostrar nombres de las columnas normalizados\n",
    "print(data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data1.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros duplicados: 1\n"
     ]
    }
   ],
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df.duplicated()\n",
    "# Contar el número de duplicados\n",
    "num_duplicados = duplicados.sum()\n",
    "print(f\"Número de registros duplicados: {num_duplicados}\")\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Manejo de valores nulos\n",
    "# Para columnas numéricas, se utiliza la media para la imputación\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['age'] = imputer.fit_transform(df[['age']])\n",
    "df['bmi'] = imputer.fit_transform(df[['bmi']])\n",
    "df['children'] = imputer.fit_transform(df[['children']])\n",
    "df['charges'] = imputer.fit_transform(df[['charges']])\n",
    "\n",
    "# 1.2 Detectar y manejar outliers (usando el IQR)\n",
    "Q1 = df['charges'].quantile(0.25)\n",
    "Q3 = df['charges'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_condition = (df['charges'] < (Q1 - 1.5 * IQR)) | (df['charges'] > (Q3 + 1.5 * IQR))\n",
    "df = df[~outlier_condition]  # Eliminamos outliers\n",
    "\n",
    "# 1.3 Creación del preprocesador\n",
    "num_features = ['age', 'bmi', 'children']\n",
    "cat_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), cat_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el pipeline que incluye el preprocesador\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Aplicamos el pipeline a los datos\n",
    "X = df.drop(columns=['charges'])  # Características\n",
    "y = df['charges']  # Variable objetivo\n",
    "X_processed = model_pipeline.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Selección de Técnica de Machine Learning\n",
    "\n",
    "1. **Entrenamiento Inicial:**\n",
    "   - Entrenar múltiples modelos de machine learning (por ejemplo, Regresión Lineal, KNN, Árbol de Decisión, Random Forest, XGBoost, LGBM).\n",
    "   - Evaluar los modelos utilizando validación cruzada y seleccionar el modelo con el mejor rendimiento inicial.\n",
    "\n",
    "2. **Comparación de Modelos:**\n",
    "   - Comparar los modelos utilizando métricas de rendimiento relevantes (exactitud, precisión, recall, F1-Score, ROC-AUC, etc.).\n",
    "   - Seleccionar la técnica de machine learning más adecuada basándose en las métricas y la naturaleza del problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 766, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 9741.562041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 766, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 9986.278805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 766, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 9683.428983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 321\n",
      "[LightGBM] [Info] Number of data points in the train set: 767, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 9755.785195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 319\n",
      "[LightGBM] [Info] Number of data points in the train set: 767, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 9910.853503\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "{'Linear Regression': np.float64(-2524.4863909848023), 'Decision Tree': np.float64(-2844.347469516961), 'Random Forest': np.float64(-2482.3705273321007), 'XGBoost': np.float64(-3018.8044464445074), 'LightGBM': np.float64(-2764.037718268913)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor()\n",
    "}\n",
    "\n",
    "# Evaluar los modelos usando validación cruzada\n",
    "model_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    model_scores[model_name] = np.mean(cv_scores)\n",
    "\n",
    "# Mostrar las puntuaciones de validación cruzada\n",
    "print(model_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionamos el modelo con el mejor desempeño\n",
    "best_model_name = min(model_scores, key=model_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Entrenamos el mejor modelo\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Optimización de Hiperparámetros\n",
    "\n",
    "1. **GridSearchCV:**\n",
    "   - Implementar `GridSearchCV` para realizar una búsqueda exhaustiva de los mejores hiperparámetros para el modelo seleccionado.\n",
    "   - Definir el espacio de búsqueda para los hiperparámetros relevantes.\n",
    "\n",
    "2. **RandomizedSearchCV:**\n",
    "   - Implementar `RandomizedSearchCV` para realizar una búsqueda aleatoria de los mejores hiperparámetros, especialmente útil si el espacio de búsqueda es grande.\n",
    "\n",
    "3. **Optuna:**\n",
    "   - Implementar `Optuna` para una optimización avanzada de los hiperparámetros, aprovechando técnicas como la optimización bayesiana y el pruning.\n",
    "\n",
    "4. **Evaluación de Modelos Optimizados:**\n",
    "   - Entrenar el modelo con los mejores hiperparámetros encontrados y evaluar su rendimiento en el conjunto de prueba.\n",
    "   - Comparar el rendimiento del modelo optimizado con el modelo inicial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Definimos los parámetros para GridSearchCV (ejemplo para Random Forest)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostramos los mejores hiperparámetros\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': None, 'min_samples_split': 16, 'n_estimators': 65}\n"
     ]
    }
   ],
   "source": [
    "# Parámetros para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 100),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_dist, n_iter=100, cv=5, scoring='neg_mean_absolute_error')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostramos los mejores hiperparámetros\n",
    "print(f\"Mejores parámetros: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 00:36:00,488] A new study created in memory with name: no-name-85b01a13-c02b-4c3c-bb95-70144a1ea050\n",
      "[I 2024-11-26 00:36:00,686] Trial 0 finished with value: 0.5804569821531931 and parameters: {'n_estimators': 78, 'max_depth': 14}. Best is trial 0 with value: 0.5804569821531931.\n",
      "[I 2024-11-26 00:36:00,988] Trial 1 finished with value: 0.5811636071300937 and parameters: {'n_estimators': 116, 'max_depth': 27}. Best is trial 1 with value: 0.5811636071300937.\n",
      "[I 2024-11-26 00:36:01,202] Trial 2 finished with value: 0.5838317388882606 and parameters: {'n_estimators': 87, 'max_depth': 12}. Best is trial 2 with value: 0.5838317388882606.\n",
      "[I 2024-11-26 00:36:01,591] Trial 3 finished with value: 0.5800642230087465 and parameters: {'n_estimators': 148, 'max_depth': 28}. Best is trial 2 with value: 0.5838317388882606.\n",
      "[I 2024-11-26 00:36:01,946] Trial 4 finished with value: 0.5805439814766684 and parameters: {'n_estimators': 155, 'max_depth': 11}. Best is trial 2 with value: 0.5838317388882606.\n",
      "[I 2024-11-26 00:36:02,156] Trial 5 finished with value: 0.5852848973316847 and parameters: {'n_estimators': 83, 'max_depth': 14}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:02,470] Trial 6 finished with value: 0.5696830393821938 and parameters: {'n_estimators': 124, 'max_depth': 14}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:02,924] Trial 7 finished with value: 0.5850628688884805 and parameters: {'n_estimators': 172, 'max_depth': 21}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:03,160] Trial 8 finished with value: 0.5830995602742961 and parameters: {'n_estimators': 90, 'max_depth': 18}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:03,570] Trial 9 finished with value: 0.5790997453365377 and parameters: {'n_estimators': 158, 'max_depth': 22}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:03,717] Trial 10 finished with value: 0.5637210401718107 and parameters: {'n_estimators': 53, 'max_depth': 17}. Best is trial 5 with value: 0.5852848973316847.\n",
      "[I 2024-11-26 00:36:04,234] Trial 11 finished with value: 0.5855097518679646 and parameters: {'n_estimators': 197, 'max_depth': 23}. Best is trial 11 with value: 0.5855097518679646.\n",
      "[I 2024-11-26 00:36:04,736] Trial 12 finished with value: 0.5892369437428194 and parameters: {'n_estimators': 189, 'max_depth': 24}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:05,265] Trial 13 finished with value: 0.5804433957606375 and parameters: {'n_estimators': 193, 'max_depth': 24}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:05,792] Trial 14 finished with value: 0.5847569711998164 and parameters: {'n_estimators': 200, 'max_depth': 24}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:06,258] Trial 15 finished with value: 0.5818413298498475 and parameters: {'n_estimators': 179, 'max_depth': 30}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:06,733] Trial 16 finished with value: 0.5878371788980552 and parameters: {'n_estimators': 180, 'max_depth': 25}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:07,193] Trial 17 finished with value: 0.5839448085717309 and parameters: {'n_estimators': 176, 'max_depth': 27}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:07,565] Trial 18 finished with value: 0.587710102148731 and parameters: {'n_estimators': 139, 'max_depth': 19}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:08,004] Trial 19 finished with value: 0.5792426433253223 and parameters: {'n_estimators': 168, 'max_depth': 25}. Best is trial 12 with value: 0.5892369437428194.\n",
      "[I 2024-11-26 00:36:08,381] Trial 20 finished with value: 0.591044117312369 and parameters: {'n_estimators': 138, 'max_depth': 30}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:08,740] Trial 21 finished with value: 0.5846728796395801 and parameters: {'n_estimators': 137, 'max_depth': 30}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:09,020] Trial 22 finished with value: 0.5724846007461878 and parameters: {'n_estimators': 106, 'max_depth': 26}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:09,505] Trial 23 finished with value: 0.5820918663689636 and parameters: {'n_estimators': 186, 'max_depth': 29}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:09,928] Trial 24 finished with value: 0.5805295663264524 and parameters: {'n_estimators': 163, 'max_depth': 26}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:10,290] Trial 25 finished with value: 0.5810002581950571 and parameters: {'n_estimators': 138, 'max_depth': 20}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:10,771] Trial 26 finished with value: 0.5818259214670369 and parameters: {'n_estimators': 184, 'max_depth': 28}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:11,159] Trial 27 finished with value: 0.5814268993943486 and parameters: {'n_estimators': 149, 'max_depth': 22}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:11,450] Trial 28 finished with value: 0.5777342140509066 and parameters: {'n_estimators': 110, 'max_depth': 25}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:11,639] Trial 29 finished with value: 0.5639016419675608 and parameters: {'n_estimators': 64, 'max_depth': 28}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:12,149] Trial 30 finished with value: 0.5817716090928784 and parameters: {'n_estimators': 188, 'max_depth': 23}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:12,521] Trial 31 finished with value: 0.5836572666975319 and parameters: {'n_estimators': 139, 'max_depth': 19}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:12,851] Trial 32 finished with value: 0.5758623177766331 and parameters: {'n_estimators': 125, 'max_depth': 16}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:13,207] Trial 33 finished with value: 0.580604489369845 and parameters: {'n_estimators': 126, 'max_depth': 20}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:13,592] Trial 34 finished with value: 0.5820106930428373 and parameters: {'n_estimators': 143, 'max_depth': 19}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:13,866] Trial 35 finished with value: 0.5861904563734066 and parameters: {'n_estimators': 102, 'max_depth': 21}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:14,266] Trial 36 finished with value: 0.5875321840777973 and parameters: {'n_estimators': 155, 'max_depth': 15}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:14,705] Trial 37 finished with value: 0.5822344542397099 and parameters: {'n_estimators': 168, 'max_depth': 27}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:15,052] Trial 38 finished with value: 0.5838590626782356 and parameters: {'n_estimators': 128, 'max_depth': 29}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:15,317] Trial 39 finished with value: 0.582846942877181 and parameters: {'n_estimators': 96, 'max_depth': 25}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:15,607] Trial 40 finished with value: 0.5782894246088948 and parameters: {'n_estimators': 114, 'max_depth': 13}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:16,013] Trial 41 finished with value: 0.5889341105784095 and parameters: {'n_estimators': 154, 'max_depth': 15}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:16,380] Trial 42 finished with value: 0.5796348795151598 and parameters: {'n_estimators': 151, 'max_depth': 12}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:16,741] Trial 43 finished with value: 0.5851867737787528 and parameters: {'n_estimators': 160, 'max_depth': 10}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:17,227] Trial 44 finished with value: 0.5846548575178373 and parameters: {'n_estimators': 179, 'max_depth': 17}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:17,599] Trial 45 finished with value: 0.5834491077814559 and parameters: {'n_estimators': 132, 'max_depth': 16}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:17,980] Trial 46 finished with value: 0.5817921173478586 and parameters: {'n_estimators': 146, 'max_depth': 18}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:18,421] Trial 47 finished with value: 0.5819891429254975 and parameters: {'n_estimators': 165, 'max_depth': 22}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:18,924] Trial 48 finished with value: 0.5885860229548704 and parameters: {'n_estimators': 193, 'max_depth': 23}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:19,456] Trial 49 finished with value: 0.5826013544384997 and parameters: {'n_estimators': 194, 'max_depth': 23}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:19,913] Trial 50 finished with value: 0.5771560424999846 and parameters: {'n_estimators': 174, 'max_depth': 24}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:20,420] Trial 51 finished with value: 0.5835187794668596 and parameters: {'n_estimators': 189, 'max_depth': 21}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:20,944] Trial 52 finished with value: 0.5851924009407263 and parameters: {'n_estimators': 200, 'max_depth': 24}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:21,426] Trial 53 finished with value: 0.5831844007456951 and parameters: {'n_estimators': 182, 'max_depth': 26}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:21,876] Trial 54 finished with value: 0.5821143142772314 and parameters: {'n_estimators': 173, 'max_depth': 22}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:22,195] Trial 55 finished with value: 0.5858842715930799 and parameters: {'n_estimators': 118, 'max_depth': 19}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:22,546] Trial 56 finished with value: 0.5835949454541614 and parameters: {'n_estimators': 133, 'max_depth': 14}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:23,065] Trial 57 finished with value: 0.5866858448086585 and parameters: {'n_estimators': 192, 'max_depth': 27}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:23,474] Trial 58 finished with value: 0.5879403086068197 and parameters: {'n_estimators': 153, 'max_depth': 20}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:23,882] Trial 59 finished with value: 0.5905108899013636 and parameters: {'n_estimators': 154, 'max_depth': 25}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:24,299] Trial 60 finished with value: 0.5850860638122789 and parameters: {'n_estimators': 153, 'max_depth': 29}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:24,717] Trial 61 finished with value: 0.5816987668597251 and parameters: {'n_estimators': 158, 'max_depth': 25}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:25,207] Trial 62 finished with value: 0.579721458603804 and parameters: {'n_estimators': 169, 'max_depth': 23}. Best is trial 20 with value: 0.591044117312369.\n",
      "[I 2024-11-26 00:36:25,626] Trial 63 finished with value: 0.5928163725496483 and parameters: {'n_estimators': 144, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:26,058] Trial 64 finished with value: 0.5841104236922687 and parameters: {'n_estimators': 143, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:26,499] Trial 65 finished with value: 0.5879701431223431 and parameters: {'n_estimators': 142, 'max_depth': 28}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:26,818] Trial 66 finished with value: 0.5804603844864216 and parameters: {'n_estimators': 120, 'max_depth': 30}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:27,186] Trial 67 finished with value: 0.5788206114171218 and parameters: {'n_estimators': 134, 'max_depth': 29}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:27,599] Trial 68 finished with value: 0.5886049667202539 and parameters: {'n_estimators': 147, 'max_depth': 28}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:28,005] Trial 69 finished with value: 0.5781249108252747 and parameters: {'n_estimators': 147, 'max_depth': 27}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:28,434] Trial 70 finished with value: 0.5800272227090927 and parameters: {'n_estimators': 163, 'max_depth': 28}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:28,813] Trial 71 finished with value: 0.5875301412475245 and parameters: {'n_estimators': 143, 'max_depth': 28}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:29,191] Trial 72 finished with value: 0.5777365157768966 and parameters: {'n_estimators': 141, 'max_depth': 30}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:29,587] Trial 73 finished with value: 0.5890885367044227 and parameters: {'n_estimators': 149, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:30,005] Trial 74 finished with value: 0.5855455757360941 and parameters: {'n_estimators': 157, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:30,398] Trial 75 finished with value: 0.5793921619672243 and parameters: {'n_estimators': 149, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:30,739] Trial 76 finished with value: 0.5909663201533222 and parameters: {'n_estimators': 131, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:31,077] Trial 77 finished with value: 0.5849203626697556 and parameters: {'n_estimators': 128, 'max_depth': 25}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:31,439] Trial 78 finished with value: 0.584054069005147 and parameters: {'n_estimators': 136, 'max_depth': 27}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:31,767] Trial 79 finished with value: 0.5849114796887583 and parameters: {'n_estimators': 122, 'max_depth': 25}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:32,131] Trial 80 finished with value: 0.587338331031951 and parameters: {'n_estimators': 131, 'max_depth': 22}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:32,519] Trial 81 finished with value: 0.5791736793448192 and parameters: {'n_estimators': 147, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:32,937] Trial 82 finished with value: 0.5802108739925236 and parameters: {'n_estimators': 160, 'max_depth': 23}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:33,245] Trial 83 finished with value: 0.5745117197828615 and parameters: {'n_estimators': 113, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:33,645] Trial 84 finished with value: 0.5837155005549527 and parameters: {'n_estimators': 151, 'max_depth': 23}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:34,025] Trial 85 finished with value: 0.5885758705910309 and parameters: {'n_estimators': 139, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:34,414] Trial 86 finished with value: 0.5819265318608119 and parameters: {'n_estimators': 145, 'max_depth': 29}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:34,606] Trial 87 finished with value: 0.5795879730266763 and parameters: {'n_estimators': 70, 'max_depth': 25}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:35,036] Trial 88 finished with value: 0.5849070165204038 and parameters: {'n_estimators': 164, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:35,498] Trial 89 finished with value: 0.5800725697716314 and parameters: {'n_estimators': 177, 'max_depth': 27}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:36,010] Trial 90 finished with value: 0.5789792889928678 and parameters: {'n_estimators': 196, 'max_depth': 21}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:36,378] Trial 91 finished with value: 0.5878944918911817 and parameters: {'n_estimators': 138, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:36,722] Trial 92 finished with value: 0.5901677128808196 and parameters: {'n_estimators': 129, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:37,066] Trial 93 finished with value: 0.5735916028438919 and parameters: {'n_estimators': 131, 'max_depth': 25}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:37,404] Trial 94 finished with value: 0.5816902974126402 and parameters: {'n_estimators': 127, 'max_depth': 23}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:37,759] Trial 95 finished with value: 0.5791937358318417 and parameters: {'n_estimators': 135, 'max_depth': 24}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:38,248] Trial 96 finished with value: 0.5882918449288997 and parameters: {'n_estimators': 185, 'max_depth': 26}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:38,576] Trial 97 finished with value: 0.5828356171339524 and parameters: {'n_estimators': 124, 'max_depth': 22}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:38,969] Trial 98 finished with value: 0.5849900624409863 and parameters: {'n_estimators': 150, 'max_depth': 23}. Best is trial 63 with value: 0.5928163725496483.\n",
      "[I 2024-11-26 00:36:39,379] Trial 99 finished with value: 0.5836113802403678 and parameters: {'n_estimators': 156, 'max_depth': 25}. Best is trial 63 with value: 0.5928163725496483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor hiperparámetro: {'n_estimators': 144, 'max_depth': 26}\n"
     ]
    }
   ],
   "source": [
    "# Definir la función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Parámetros a optimizar\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)  # Usamos R^2 como métrica\n",
    "    return score\n",
    "\n",
    "# Crear el estudio Optuna y optimizar\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Mostrar el mejor resultado encontrado\n",
    "print(f\"Mejor hiperparámetro: {study.best_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
